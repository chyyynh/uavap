{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAV AIP Detection API (Colab GPU)\n",
    "\n",
    "在 Google Colab 上執行 UAV 物件偵測 API，使用免費 GPU 加速推論。\n",
    "\n",
    "## 使用方式\n",
    "1. 執行所有 Cell\n",
    "2. 複製最後產生的 Cloudflare Tunnel URL\n",
    "3. 在前端 Dashboard 貼上 URL 連線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. 安裝依賴\n!pip install -q fastapi uvicorn nest-asyncio \\\n    ultralytics rasterio laspy[lazrs] pyproj shapely \\\n    segmentation-models-pytorch huggingface_hub pillow\n\n# 安裝 cloudflared\n!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared\n!chmod +x /usr/local/bin/cloudflared\nprint(\"依賴安裝完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. API 程式碼\nimport threading\nimport time\nimport os\nimport shutil\nimport io\nimport math\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport numpy as np\nfrom fastapi import FastAPI, UploadFile, File, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import Response\nfrom pydantic import BaseModel\n\n# FastAPI App\napp = FastAPI(title=\"UAV Object Detection API - Colab GPU\")\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# 設定\nUPLOAD_DIR = Path(\"/content/uploads\")\nUPLOAD_DIR.mkdir(parents=True, exist_ok=True)\nMODEL_DIR = Path(\"/content/models\")\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\nHF_MODEL_REPO = \"chyyynh/uav-yolo-models\"\n\ndef get_model_path(filename: str) -> Path:\n    cached_path = MODEL_DIR / filename\n    if cached_path.exists():\n        return cached_path\n    try:\n        from huggingface_hub import hf_hub_download\n        print(f\"[Model] Downloading {filename}...\")\n        downloaded = hf_hub_download(repo_id=HF_MODEL_REPO, filename=filename)\n        return Path(downloaded)\n    except Exception as e:\n        print(f\"[Model] Failed: {e}\")\n        return cached_path\n\n# YOLO 設定\nMODELS_CONFIG = {\n    \"car\": {\"filename\": \"vehicle.pt\", \"conf\": 0.75, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (4.0, 25.0), \"ratio\": (1.0, 3.0)},\n    \"person\": {\"filename\": \"human.pt\", \"conf\": 0.60, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (0.2, 1.0), \"ratio\": (0.5, 2.0)},\n    \"cone\": {\"filename\": \"cone.pt\", \"conf\": 0.60, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (0.05, 0.5), \"ratio\": (0.8, 1.4)},\n}\n\nHEIGHT_RANGE = {\"person\": (1.45, 1.90), \"cone\": (0.25, 0.90), \"car\": (1.0, 2.2), \"vehicle\": (1.0, 2.2)}\nHEIGHT_PRIOR = {\"person\": {\"mean\": 1.70, \"std\": 0.08}, \"cone\": {\"mean\": 0.45, \"std\": 0.10}, \"car\": {\"mean\": 1.60, \"std\": 0.25}, \"vehicle\": {\"mean\": 1.60, \"std\": 0.25}}\nMIN_PTS_BY_CLASS = {\"person\": 8, \"cone\": 10, \"car\": 30}\n\n# UPerNet 設定\nLANDCOVER_CLASSES = {0: \"bare-ground\", 1: \"tree\", 2: \"road\", 3: \"pavement\", 4: \"grass\", 5: \"building\"}\nLANDCOVER_COLORS = {\"bare-ground\": [222, 184, 135], \"tree\": [34, 139, 34], \"road\": [128, 128, 128], \"pavement\": [178, 34, 34], \"grass\": [124, 252, 0], \"building\": [255, 140, 0]}\nUPERNET_CONFIG = {\"filename\": \"UPerNet_best.pth\", \"num_classes\": 6, \"tile_size\": (64, 64), \"overlap\": 0.5, \"encoder_name\": \"resnet50\"}\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\n# Terrain 設定\nSLOPE_CATEGORIES = {\"flat\": (0, 5), \"gentle\": (5, 15), \"moderate\": (15, 30), \"steep\": (30, 90)}\nASPECT_DIRECTIONS = {\"N\": (337.5, 22.5), \"NE\": (22.5, 67.5), \"E\": (67.5, 112.5), \"SE\": (112.5, 157.5),\n                     \"S\": (157.5, 202.5), \"SW\": (202.5, 247.5), \"W\": (247.5, 292.5), \"NW\": (292.5, 337.5)}\n\nrng = np.random.default_rng(42)\n\n# 全域狀態\nuploaded_files = {\"ortho\": None, \"laz\": None, \"dsm\": None}\northo_cache = {\"src\": None, \"transform\": None, \"crs\": None, \"bounds\": None, \"width\": 0, \"height\": 0, \"pixel_w\": 0, \"pixel_h\": 0}\npointcloud_cache = {\"X\": None, \"Y\": None, \"Z\": None, \"loaded\": False}\ndsm_cache = {\"data\": None, \"transform\": None, \"crs\": None, \"loaded\": False, \"nodata\": None, \"resolution\": None}\nmodels_cache = {\"loaded\": False, \"models\": {}}\nupernet_cache = {\"loaded\": False, \"model\": None, \"device\": None}\nlandcover_cache = {\"mask\": None, \"stats\": None, \"computed\": False}\nterrain_cache = {\"slope\": None, \"aspect\": None, \"stats\": None, \"computed\": False}\nprocessing_state = {\"job_id\": None, \"status\": \"idle\", \"progress\": 0, \"current_step\": \"\", \"elapsed_seconds\": 0, \"results\": [], \"start_time\": None}\n\nclass ProcessingRequest(BaseModel):\n    project_id: str = \"current\"\n    detect_person: bool = True\n    detect_vehicle: bool = True\n    detect_cone: bool = True\n    include_elevation: bool = True\n    include_landcover: bool = False\n    include_terrain: bool = False\n\ndef load_yolo_models():\n    if models_cache[\"loaded\"]:\n        return models_cache[\"models\"]\n    from ultralytics import YOLO\n    models = {}\n    for cls_name, cfg in MODELS_CONFIG.items():\n        model_path = get_model_path(cfg[\"filename\"])\n        if model_path.exists():\n            models[cls_name] = YOLO(str(model_path))\n            print(f\"[YOLO] Loaded: {cls_name}\")\n    models_cache[\"models\"] = models\n    models_cache[\"loaded\"] = True\n    return models\n\n# ============ UPerNet Landcover Functions ============\n\ndef load_upernet_model():\n    \"\"\"載入 UPerNet 模型\"\"\"\n    if upernet_cache[\"loaded\"]:\n        return upernet_cache[\"model\"]\n\n    try:\n        import torch\n        import segmentation_models_pytorch as smp\n    except ImportError as e:\n        print(f\"[UPerNet] Missing dependency: {e}\")\n        return None\n\n    model_path = get_model_path(UPERNET_CONFIG[\"filename\"])\n    if not model_path.exists():\n        print(f\"[UPerNet] Model not found: {model_path}\")\n        return None\n\n    try:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = smp.UPerNet(\n            encoder_name=UPERNET_CONFIG[\"encoder_name\"],\n            encoder_weights=None,\n            in_channels=3,\n            classes=UPERNET_CONFIG[\"num_classes\"]\n        ).to(device)\n\n        state_dict = torch.load(str(model_path), map_location=device)\n        model.load_state_dict(state_dict, strict=False)\n        model.eval()\n\n        upernet_cache[\"model\"] = model\n        upernet_cache[\"loaded\"] = True\n        upernet_cache[\"device\"] = device\n        print(f\"[UPerNet] Loaded on {device}\")\n        return model\n    except Exception as e:\n        print(f\"[UPerNet] Failed to load: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\ndef run_landcover_segmentation(progress_callback=None) -> dict:\n    \"\"\"執行土地覆蓋分割\"\"\"\n    import torch\n    import torchvision.transforms as T\n    import cv2\n\n    if ortho_cache[\"src\"] is None:\n        raise ValueError(\"No ortho image loaded\")\n\n    model = load_upernet_model()\n    if model is None:\n        raise ValueError(\"Failed to load UPerNet model\")\n\n    device = upernet_cache[\"device\"]\n    src = ortho_cache[\"src\"]\n\n    # Read image\n    data = src.read([1, 2, 3])\n    img = np.moveaxis(data, 0, -1)\n\n    # Normalize to uint8 if needed\n    if img.dtype != np.uint8:\n        img = img.astype(np.float32)\n        img = (img - img.min()) / max(img.max() - img.min(), 1e-6) * 255\n        img = img.astype(np.uint8)\n\n    H, W = img.shape[:2]\n    th, tw = UPERNET_CONFIG[\"tile_size\"]\n    overlap = UPERNET_CONFIG[\"overlap\"]\n    num_classes = UPERNET_CONFIG[\"num_classes\"]\n\n    stride_h = max(1, int(th * (1 - overlap)))\n    stride_w = max(1, int(tw * (1 - overlap)))\n\n    # Padding\n    pad_h = max(((H - th) // stride_h + 1) * stride_h + th - H, 0)\n    pad_w = max(((W - tw) // stride_w + 1) * stride_w + tw - W, 0)\n    img_pad = cv2.copyMakeBorder(img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT_101)\n    Hp, Wp = img_pad.shape[:2]\n\n    # Accumulators\n    logit_sum = np.zeros((num_classes, Hp, Wp), np.float32)\n    count = np.zeros((Hp, Wp), np.float32)\n\n    to_tensor = T.Compose([\n        T.ToTensor(),\n        T.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n    ])\n\n    # Calculate total tiles for progress\n    total_tiles = ((Hp - th) // stride_h + 1) * ((Wp - tw) // stride_w + 1)\n    tile_count = 0\n\n    # Sliding window inference\n    with torch.no_grad():\n        for y in range(0, Hp - th + 1, stride_h):\n            for x in range(0, Wp - tw + 1, stride_w):\n                tile = img_pad[y:y+th, x:x+tw]\n                tin = to_tensor(tile).unsqueeze(0).to(device)\n                logits = model(tin)\n                logits = logits[0] if isinstance(logits, (list, tuple)) else logits\n                logit_sum[:, y:y+th, x:x+tw] += logits.squeeze(0).cpu().numpy()\n                count[y:y+th, x:x+tw] += 1\n\n                tile_count += 1\n                if progress_callback and tile_count % 100 == 0:\n                    progress = int(tile_count / total_tiles * 100)\n                    progress_callback(progress, f\"Landcover segmentation ({tile_count}/{total_tiles})...\")\n\n    # Get prediction\n    pred = np.argmax(logit_sum / np.maximum(count, 1e-6), axis=0).astype(np.uint8)\n    pred = pred[:H, :W]\n\n    # Handle nodata (black pixels)\n    black_mask = np.all(img <= 10, axis=2)\n    pred[black_mask] = 255\n\n    # Compute statistics\n    stats = {}\n    total_valid = np.sum(pred < num_classes)\n    for class_id, class_name in LANDCOVER_CLASSES.items():\n        class_pixels = np.sum(pred == class_id)\n        stats[class_name] = {\n            \"pixels\": int(class_pixels),\n            \"percentage\": round(class_pixels / total_valid * 100, 2) if total_valid > 0 else 0\n        }\n\n    # Cache results\n    landcover_cache[\"mask\"] = pred\n    landcover_cache[\"stats\"] = stats\n    landcover_cache[\"computed\"] = True\n\n    print(f\"[UPerNet] Segmentation complete: {H}x{W}\")\n    return {\"stats\": stats, \"shape\": (H, W)}\n\ndef get_landcover_colorized() -> np.ndarray:\n    \"\"\"取得彩色土地覆蓋圖\"\"\"\n    if not landcover_cache[\"computed\"] or landcover_cache[\"mask\"] is None:\n        return None\n\n    mask = landcover_cache[\"mask\"]\n    H, W = mask.shape\n    color_img = np.zeros((H, W, 3), dtype=np.uint8)\n\n    for class_id, class_name in LANDCOVER_CLASSES.items():\n        color = LANDCOVER_COLORS[class_name]\n        color_img[mask == class_id] = color\n\n    # Set nodata to black\n    color_img[mask == 255] = [0, 0, 0]\n\n    return color_img\n\n# ============ Terrain Analysis Functions ============\n\ndef compute_terrain_metrics(progress_callback=None) -> dict:\n    \"\"\"從 DSM 計算 slope 和 aspect\"\"\"\n    if not dsm_cache[\"loaded\"]:\n        raise ValueError(\"No DSM loaded\")\n\n    arr = dsm_cache[\"data\"].astype(np.float32)\n    nodata = dsm_cache[\"nodata\"]\n    resolution = dsm_cache[\"resolution\"] or 1.0\n\n    # Handle nodata\n    if nodata is not None:\n        arr[arr == nodata] = np.nan\n\n    if progress_callback:\n        progress_callback(10, \"Computing gradients...\")\n\n    # Compute gradients\n    grad_y, grad_x = np.gradient(arr, resolution, resolution)\n\n    if progress_callback:\n        progress_callback(40, \"Computing slope...\")\n\n    # Slope (degrees)\n    slope = np.degrees(np.arctan(np.sqrt(grad_x**2 + grad_y**2)))\n\n    if progress_callback:\n        progress_callback(60, \"Computing aspect...\")\n\n    # Aspect (0-360 degrees)\n    aspect = np.degrees(np.arctan2(-grad_x, grad_y))\n    aspect[aspect < 0] += 360\n\n    if progress_callback:\n        progress_callback(80, \"Computing statistics...\")\n\n    # Compute statistics - filter out NaN values\n    valid_mask = ~np.isnan(arr) & ~np.isnan(slope) & ~np.isnan(aspect)\n    valid_slope = slope[valid_mask]\n    valid_aspect = aspect[valid_mask]\n    valid_elev = arr[valid_mask]\n\n    # Elevation stats (with NaN safety)\n    def safe_stat(arr, func, default=0.0):\n        if len(arr) == 0:\n            return default\n        result = func(arr)\n        if np.isnan(result) or np.isinf(result):\n            return default\n        return float(result)\n\n    elevation_stats = {\n        \"min\": safe_stat(valid_elev, np.min),\n        \"max\": safe_stat(valid_elev, np.max),\n        \"mean\": safe_stat(valid_elev, np.mean),\n        \"std\": safe_stat(valid_elev, np.std),\n    }\n\n    # Slope distribution by category\n    slope_distribution = {}\n    total_valid = len(valid_slope)\n    for cat_name, (low, high) in SLOPE_CATEGORIES.items():\n        count = int(np.sum((valid_slope >= low) & (valid_slope < high)))\n        slope_distribution[cat_name] = {\n            \"count\": count,\n            \"percentage\": round(count / total_valid * 100, 2) if total_valid > 0 else 0.0\n        }\n\n    slope_stats = {\n        \"min\": safe_stat(valid_slope, np.min),\n        \"max\": safe_stat(valid_slope, np.max),\n        \"mean\": safe_stat(valid_slope, np.mean),\n        \"distribution\": slope_distribution,\n    }\n\n    # Aspect distribution by direction\n    aspect_distribution = {}\n    for dir_name, (low, high) in ASPECT_DIRECTIONS.items():\n        if dir_name == \"N\":  # Special case: wraps around 360\n            count = int(np.sum((valid_aspect >= low) | (valid_aspect < high)))\n        else:\n            count = int(np.sum((valid_aspect >= low) & (valid_aspect < high)))\n        aspect_distribution[dir_name] = {\n            \"count\": count,\n            \"percentage\": round(count / total_valid * 100, 2) if total_valid > 0 else 0.0\n        }\n\n    aspect_stats = {\n        \"distribution\": aspect_distribution,\n    }\n\n    stats = {\n        \"elevation\": elevation_stats,\n        \"slope\": slope_stats,\n        \"aspect\": aspect_stats,\n    }\n\n    # Cache results\n    terrain_cache[\"slope\"] = slope\n    terrain_cache[\"aspect\"] = aspect\n    terrain_cache[\"stats\"] = stats\n    terrain_cache[\"computed\"] = True\n\n    if progress_callback:\n        progress_callback(100, \"Terrain analysis complete\")\n\n    print(f\"[Terrain] Analysis complete: {arr.shape}\")\n    return stats\n\ndef get_slope_colorized() -> np.ndarray:\n    \"\"\"取得彩色坡度圖 (terrain colormap)\"\"\"\n    if not terrain_cache[\"computed\"] or terrain_cache[\"slope\"] is None:\n        return None\n\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import Normalize\n\n    slope = terrain_cache[\"slope\"]\n    norm = Normalize(vmin=0, vmax=60)\n    cmap = plt.cm.terrain\n\n    # Apply colormap\n    colored = cmap(norm(slope))[:, :, :3]  # Remove alpha channel\n    colored = (colored * 255).astype(np.uint8)\n\n    # Handle NaN as black\n    nan_mask = np.isnan(slope)\n    colored[nan_mask] = [0, 0, 0]\n\n    return colored\n\ndef get_aspect_colorized() -> np.ndarray:\n    \"\"\"取得彩色坡向圖 (HSV colormap)\"\"\"\n    if not terrain_cache[\"computed\"] or terrain_cache[\"aspect\"] is None:\n        return None\n\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import Normalize\n\n    aspect = terrain_cache[\"aspect\"]\n    norm = Normalize(vmin=0, vmax=360)\n    cmap = plt.cm.hsv\n\n    # Apply colormap\n    colored = cmap(norm(aspect))[:, :, :3]  # Remove alpha channel\n    colored = (colored * 255).astype(np.uint8)\n\n    # Handle NaN as black\n    nan_mask = np.isnan(aspect)\n    colored[nan_mask] = [0, 0, 0]\n\n    return colored\n\n# ============ YOLO Detection Functions ============\n\ndef run_yolo_detection(classes_to_detect: list[str], progress_callback=None) -> list[dict]:\n    import rasterio\n    from rasterio.windows import Window\n    import torch\n    from torchvision.ops import nms\n\n    if ortho_cache[\"src\"] is None:\n        raise ValueError(\"No ortho image loaded\")\n\n    src = ortho_cache[\"src\"]\n    transform = ortho_cache[\"transform\"]\n    width, height = ortho_cache[\"width\"], ortho_cache[\"height\"]\n    pixel_w, pixel_h = ortho_cache[\"pixel_w\"], ortho_cache[\"pixel_h\"]\n\n    models = load_yolo_models()\n    if not models:\n        raise ValueError(\"No YOLO models loaded\")\n\n    raw_detections = []\n    total_classes = len(classes_to_detect)\n\n    for cls_idx, cls_name in enumerate(classes_to_detect):\n        if cls_name not in models:\n            continue\n        model = models[cls_name]\n        cfg = MODELS_CONFIG[cls_name]\n        patch_size = cfg[\"patch_size\"]\n        step = patch_size - cfg[\"overlap\"]\n\n        rows = list(range(0, height, step))\n        total_patches = len(rows) * ((width + step - 1) // step)\n        patch_count = 0\n\n        for y in rows:\n            for x in range(0, width, step):\n                win_w, win_h = min(patch_size, width - x), min(patch_size, height - y)\n                patch = src.read(window=Window(x, y, win_w, win_h))\n                patch = np.moveaxis(patch[:3], 0, -1)\n\n                if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n                    padded = np.zeros((patch_size, patch_size, 3), dtype=patch.dtype)\n                    padded[:patch.shape[0], :patch.shape[1]] = patch\n                    patch = padded\n\n                results = model(patch, conf=cfg[\"conf\"], verbose=False)\n                for result in results:\n                    boxes = result.boxes\n                    if boxes is None:\n                        continue\n                    for i in range(len(boxes)):\n                        bx = boxes.xyxy[i].cpu().numpy()\n                        conf = float(boxes.conf[i].cpu())\n                        raw_detections.append({\"class\": cls_name, \"conf\": conf, \"px1\": x + bx[0], \"py1\": y + bx[1], \"px2\": x + bx[2], \"py2\": y + bx[3]})\n\n                patch_count += 1\n                if progress_callback and patch_count % 10 == 0:\n                    progress = 20 + (cls_idx / total_classes) * 50 + (patch_count / total_patches) * (50 / total_classes)\n                    progress_callback(int(progress), f\"Detecting {cls_name}...\")\n\n    print(f\"[YOLO] Raw: {len(raw_detections)}\")\n\n    # NMS\n    final_detections = []\n    for cls_name in classes_to_detect:\n        if cls_name not in MODELS_CONFIG:\n            continue\n        cfg = MODELS_CONFIG[cls_name]\n        cls_raw = [r for r in raw_detections if r[\"class\"] == cls_name]\n        if not cls_raw:\n            continue\n        boxes = torch.tensor([[r[\"px1\"], r[\"py1\"], r[\"px2\"], r[\"py2\"]] for r in cls_raw])\n        scores = torch.tensor([r[\"conf\"] for r in cls_raw])\n        keep = nms(boxes, scores, cfg[\"nms_iou\"])\n        final_detections.extend([cls_raw[int(i)] for i in keep])\n\n    print(f\"[YOLO] After NMS: {len(final_detections)}\")\n\n    # OBIA filter\n    records = []\n    id_counter = {k: 0 for k in MODELS_CONFIG}\n    for r in final_detections:\n        cls_name = r[\"class\"]\n        cfg = MODELS_CONFIG[cls_name]\n        w_m = (r[\"px2\"] - r[\"px1\"]) * pixel_w\n        h_m = (r[\"py2\"] - r[\"py1\"]) * pixel_h\n        area = w_m * h_m\n        aspect = max(w_m, h_m) / (min(w_m, h_m) + 1e-6)\n        if not (cfg[\"area\"][0] <= area <= cfg[\"area\"][1]):\n            continue\n        if not (cfg[\"ratio\"][0] <= aspect <= cfg[\"ratio\"][1]):\n            continue\n\n        id_counter[cls_name] += 1\n        cx, cy = (r[\"px1\"] + r[\"px2\"]) / 2, (r[\"py1\"] + r[\"py2\"]) / 2\n        gx, gy = transform * (cx, cy)\n        records.append({\"id\": id_counter[cls_name], \"cls\": \"vehicle\" if cls_name == \"car\" else cls_name, \"score\": round(r[\"conf\"], 3),\n                        \"center_x\": round(gx, 2), \"center_y\": round(gy, 2), \"area_m2\": round(area, 2), \"aspect_rat\": round(aspect, 2),\n                        \"px1\": r[\"px1\"], \"py1\": r[\"py1\"], \"px2\": r[\"px2\"], \"py2\": r[\"py2\"], \"elev_z\": 0.0, \"height_m\": 0.0, \"lat\": 0.0, \"lon\": 0.0})\n\n    print(f\"[YOLO] After OBIA: {len(records)}\")\n    return records\n\ndef sample_trunc_normal(mean, std, low, high):\n    for _ in range(60):\n        v = rng.normal(mean, std)\n        if low <= v <= high:\n            return float(v)\n    return float(rng.uniform(low, high))\n\ndef impute_height_by_class(cls_name, h_raw, n_pts, min_pts):\n    hmin, hmax = HEIGHT_RANGE.get(cls_name, (0.0, float('inf')))\n    prior = HEIGHT_PRIOR.get(cls_name, {\"mean\": (hmin + hmax) / 2.0, \"std\": 0.1})\n    def draw():\n        return sample_trunc_normal(prior[\"mean\"], prior[\"std\"], hmin, hmax)\n    if n_pts == 0 or not np.isfinite(h_raw) or h_raw < hmin or h_raw > hmax:\n        return draw(), \"imputed\"\n    return float(h_raw), \"ok\"\n\ndef compute_height_volume(detections, progress_callback=None):\n    if not pointcloud_cache[\"loaded\"]:\n        for det in detections:\n            cls = det[\"cls\"] if det[\"cls\"] != \"vehicle\" else \"car\"\n            h, _ = impute_height_by_class(cls, np.nan, 0, 100)\n            det[\"height_m\"] = round(h, 2)\n        return detections\n\n    from shapely.geometry import box\n    X, Y, Z = pointcloud_cache[\"X\"], pointcloud_cache[\"Y\"], pointcloud_cache[\"Z\"]\n    transform = ortho_cache[\"transform\"]\n\n    for det in detections:\n        cls = det[\"cls\"] if det[\"cls\"] != \"vehicle\" else \"car\"\n        px1, py1 = transform * (det[\"px1\"], det[\"py1\"])\n        px2, py2 = transform * (det[\"px2\"], det[\"py2\"])\n        geom = box(min(px1, px2), min(py1, py2), max(px1, px2), max(py1, py2))\n        minx, miny, maxx, maxy = geom.bounds\n        m = (X >= minx) & (X <= maxx) & (Y >= miny) & (Y <= maxy)\n        if np.any(m):\n            zz = Z[m]\n            z0 = float(np.percentile(zz, 5))\n            ztop = float(np.percentile(zz, 95))\n            h_raw = max(0.0, ztop - z0)\n            h_fix, _ = impute_height_by_class(cls, h_raw, len(zz), MIN_PTS_BY_CLASS.get(cls, 30))\n            det[\"height_m\"] = round(h_fix, 2)\n            det[\"elev_z\"] = round(z0, 1)\n        else:\n            h, _ = impute_height_by_class(cls, np.nan, 0, 100)\n            det[\"height_m\"] = round(h, 2)\n    return detections\n\ndef add_latlon_to_detections(detections):\n    if ortho_cache[\"crs\"] is None:\n        return detections\n    try:\n        from pyproj import Transformer\n        transformer = Transformer.from_crs(ortho_cache[\"crs\"], \"EPSG:4326\", always_xy=True)\n        for det in detections:\n            lon, lat = transformer.transform(det[\"center_x\"], det[\"center_y\"])\n            det[\"lat\"], det[\"lon\"] = round(lat, 6), round(lon, 6)\n    except Exception as e:\n        print(f\"[Coord] Error: {e}\")\n    return detections\n\n# ============ Data Loading Functions ============\n\ndef load_ortho_image(tiff_path):\n    import rasterio\n    src = rasterio.open(tiff_path)\n    ortho_cache[\"src\"] = src\n    ortho_cache[\"transform\"] = src.transform\n    ortho_cache[\"crs\"] = src.crs\n    ortho_cache[\"width\"], ortho_cache[\"height\"] = src.width, src.height\n    ortho_cache[\"pixel_w\"], ortho_cache[\"pixel_h\"] = src.res\n    bounds = src.bounds\n    try:\n        from pyproj import Transformer\n        transformer = Transformer.from_crs(src.crs, \"EPSG:4326\", always_xy=True)\n        west, south = transformer.transform(bounds.left, bounds.bottom)\n        east, north = transformer.transform(bounds.right, bounds.top)\n        ortho_cache[\"bounds\"] = {\"north\": north, \"south\": south, \"east\": east, \"west\": west}\n    except:\n        ortho_cache[\"bounds\"] = {\"north\": bounds.top, \"south\": bounds.bottom, \"east\": bounds.right, \"west\": bounds.left}\n    print(f\"[Ortho] Loaded: {src.width}x{src.height}\")\n\ndef load_point_cloud(laz_path):\n    import laspy\n    las = laspy.read(laz_path)\n    pointcloud_cache[\"X\"] = np.asarray(las.x)\n    pointcloud_cache[\"Y\"] = np.asarray(las.y)\n    pointcloud_cache[\"Z\"] = np.asarray(las.z)\n    pointcloud_cache[\"loaded\"] = True\n    print(f\"[PointCloud] Loaded {len(pointcloud_cache['Z'])} points\")\n\ndef load_dsm(dsm_path):\n    import rasterio\n    src = rasterio.open(dsm_path)\n    dsm_cache[\"data\"] = src.read(1)\n    dsm_cache[\"transform\"] = src.transform\n    dsm_cache[\"crs\"] = src.crs\n    dsm_cache[\"nodata\"] = src.nodata\n    dsm_cache[\"loaded\"] = True\n    dsm_cache[\"resolution\"] = src.res[0]\n    print(f\"[DSM] Loaded: {src.width}x{src.height}\")\n    src.close()\n\ndef convert_numpy(obj):\n    \"\"\"Convert numpy types to Python types, handling NaN and Inf values for JSON serialization.\"\"\"\n    if isinstance(obj, dict):\n        return {k: convert_numpy(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_numpy(v) for v in obj]\n    elif isinstance(obj, np.floating):\n        val = float(obj)\n        if math.isnan(val) or math.isinf(val):\n            return None\n        return val\n    elif isinstance(obj, float):\n        if math.isnan(obj) or math.isinf(obj):\n            return None\n        return obj\n    elif isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.ndarray):\n        return convert_numpy(obj.tolist())\n    return obj\n\n# ============ API 端點 ============\n\n@app.get(\"/\")\nasync def root():\n    return {\"status\": \"ok\", \"message\": \"UAV Object Detection API - Colab GPU\"}\n\n@app.get(\"/api/projects\")\nasync def get_projects():\n    return [{\"id\": \"current\", \"name\": \"Current Project\"}]\n\n@app.get(\"/api/detections/{project_id}\")\nasync def get_detections(project_id: str):\n    return convert_numpy(processing_state[\"results\"] or [])\n\n@app.get(\"/api/gpu/status\")\nasync def get_gpu_status():\n    try:\n        import torch\n        if torch.cuda.is_available():\n            return {\"name\": torch.cuda.get_device_name(0), \"status\": \"online\"}\n    except:\n        pass\n    return {\"name\": \"CPU Mode\", \"status\": \"offline\"}\n\n@app.get(\"/api/ortho/bounds\")\nasync def get_ortho_bounds():\n    return ortho_cache[\"bounds\"] or {\"error\": \"No image loaded\"}\n\n@app.get(\"/api/ortho/image\")\nasync def get_ortho_image(max_width: int = None, quality: int = 85):\n    \"\"\"取得正射影像 (JPEG with compression)\"\"\"\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=404, detail=\"No image loaded\")\n    from PIL import Image\n    src = ortho_cache[\"src\"]\n    data = src.read([1, 2, 3])\n    data = np.moveaxis(data, 0, -1)\n    if data.dtype != np.uint8:\n        data = ((data - data.min()) / (data.max() - data.min() + 1e-6) * 255).astype(np.uint8)\n    img = Image.fromarray(data)\n    # Resize if max_width specified\n    if max_width and img.width > max_width:\n        ratio = max_width / img.width\n        new_height = int(img.height * ratio)\n        img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"JPEG\", quality=min(95, max(1, quality)), optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/jpeg\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.get(\"/api/ortho/preview\")\nasync def get_ortho_preview(width: int = 800, height: int = 600, quality: int = 85):\n    \"\"\"取得正射影像預覽 (JPEG with compression)\"\"\"\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=404, detail=\"No image loaded\")\n    from PIL import Image\n    src = ortho_cache[\"src\"]\n    data = src.read([1, 2, 3])\n    data = np.moveaxis(data, 0, -1)\n    if data.dtype != np.uint8:\n        data = ((data - data.min()) / (data.max() - data.min() + 1e-6) * 255).astype(np.uint8)\n    img = Image.fromarray(data)\n    img.thumbnail((width, height), Image.Resampling.LANCZOS)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"JPEG\", quality=min(95, max(1, quality)), optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/jpeg\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.get(\"/api/ortho/metadata\")\nasync def get_ortho_metadata():\n    if ortho_cache[\"src\"] is None:\n        return {\"error\": \"No image loaded\"}\n    src = ortho_cache[\"src\"]\n    return {\n        \"filename\": Path(uploaded_files[\"ortho\"]).name if uploaded_files[\"ortho\"] else None,\n        \"datetime\": datetime.now().isoformat(),\n        \"width\": src.width,\n        \"height\": src.height,\n        \"crs\": str(src.crs) if src.crs else None,\n        \"pixel_w\": ortho_cache[\"pixel_w\"],\n        \"pixel_h\": ortho_cache[\"pixel_h\"],\n    }\n\n@app.post(\"/api/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    filename = file.filename.lower()\n    file_path = UPLOAD_DIR / file.filename\n    with open(file_path, \"wb\") as f:\n        shutil.copyfileobj(file.file, f)\n    if filename.endswith((\".tif\", \".tiff\")):\n        uploaded_files[\"ortho\"] = str(file_path)\n        load_ortho_image(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"Image uploaded\", \"type\": \"ortho\"}\n    elif filename.endswith((\".laz\", \".las\")):\n        uploaded_files[\"laz\"] = str(file_path)\n        load_point_cloud(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"Point cloud uploaded\", \"type\": \"laz\", \"points\": len(pointcloud_cache[\"Z\"])}\n    return {\"filename\": file.filename, \"message\": \"File uploaded\", \"type\": \"unknown\"}\n\n@app.post(\"/api/upload/dsm\")\nasync def upload_dsm(file: UploadFile = File(...)):\n    filename = file.filename.lower()\n    file_path = UPLOAD_DIR / file.filename\n    with open(file_path, \"wb\") as f:\n        shutil.copyfileobj(file.file, f)\n    if filename.endswith((\".tif\", \".tiff\")):\n        uploaded_files[\"dsm\"] = str(file_path)\n        load_dsm(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"DSM uploaded\", \"type\": \"dsm\", \"resolution\": dsm_cache.get(\"resolution\")}\n    raise HTTPException(status_code=400, detail=\"DSM must be a GeoTIFF file\")\n\n# ============ Landcover API Endpoints ============\n\n@app.get(\"/api/landcover/status\")\nasync def get_landcover_status():\n    return {\"computed\": landcover_cache[\"computed\"], \"has_stats\": landcover_cache[\"stats\"] is not None}\n\n@app.get(\"/api/landcover/stats\")\nasync def get_landcover_stats():\n    if not landcover_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Landcover not computed yet\")\n    return convert_numpy({\"classes\": LANDCOVER_CLASSES, \"colors\": LANDCOVER_COLORS, \"stats\": landcover_cache[\"stats\"]})\n\n@app.get(\"/api/landcover/image\")\nasync def get_landcover_image(max_width: int = None):\n    \"\"\"取得土地覆蓋彩色圖 (PNG with compression)\"\"\"\n    if not landcover_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Landcover not computed yet\")\n    from PIL import Image\n    color_img = get_landcover_colorized()\n    if color_img is None:\n        raise HTTPException(status_code=500, detail=\"Failed to generate colorized landcover\")\n    img = Image.fromarray(color_img)\n    if max_width and img.width > max_width:\n        ratio = max_width / img.width\n        new_height = int(img.height * ratio)\n        img = img.resize((max_width, new_height), Image.Resampling.NEAREST)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\", optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/png\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.get(\"/api/landcover/overlay\")\nasync def get_landcover_overlay(alpha: float = 0.5, max_width: int = None, quality: int = 85):\n    \"\"\"取得土地覆蓋疊加圖 (JPEG with compression)\"\"\"\n    if not landcover_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Landcover not computed yet\")\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=400, detail=\"No ortho image loaded\")\n    from PIL import Image\n    src = ortho_cache[\"src\"]\n    data = src.read([1, 2, 3])\n    ortho_img = np.moveaxis(data, 0, -1)\n    if ortho_img.dtype != np.uint8:\n        ortho_img = ((ortho_img - ortho_img.min()) / (ortho_img.max() - ortho_img.min() + 1e-6) * 255).astype(np.uint8)\n    color_img = get_landcover_colorized()\n    if color_img is None:\n        raise HTTPException(status_code=500, detail=\"Failed to generate colorized landcover\")\n    mask = landcover_cache[\"mask\"]\n    valid_mask = (mask < UPERNET_CONFIG[\"num_classes\"]).astype(np.float32)\n    blended = ortho_img.astype(np.float32) * (1 - alpha * valid_mask[:, :, np.newaxis]) + \\\n              color_img.astype(np.float32) * alpha * valid_mask[:, :, np.newaxis]\n    blended = np.clip(blended, 0, 255).astype(np.uint8)\n    img = Image.fromarray(blended)\n    if max_width and img.width > max_width:\n        ratio = max_width / img.width\n        new_height = int(img.height * ratio)\n        img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"JPEG\", quality=min(95, max(1, quality)), optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/jpeg\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.post(\"/api/landcover/run\")\nasync def run_landcover():\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=400, detail=\"Please upload an image first\")\n    try:\n        result = run_landcover_segmentation()\n        return convert_numpy({\"status\": \"done\", \"stats\": result[\"stats\"], \"shape\": result[\"shape\"]})\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# ============ Terrain API Endpoints ============\n\n@app.get(\"/api/terrain/status\")\nasync def get_terrain_status():\n    return {\"computed\": terrain_cache[\"computed\"], \"has_stats\": terrain_cache[\"stats\"] is not None, \"dsm_loaded\": dsm_cache[\"loaded\"]}\n\n@app.get(\"/api/terrain/stats\")\nasync def get_terrain_stats():\n    if not terrain_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Terrain not computed yet\")\n    return convert_numpy(terrain_cache[\"stats\"])\n\n@app.get(\"/api/terrain/slope\")\nasync def get_terrain_slope(max_width: int = None):\n    \"\"\"取得坡度彩色圖 (PNG with compression)\"\"\"\n    if not terrain_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Terrain not computed yet\")\n    from PIL import Image\n    color_img = get_slope_colorized()\n    if color_img is None:\n        raise HTTPException(status_code=500, detail=\"Failed to generate colorized slope\")\n    img = Image.fromarray(color_img)\n    if max_width and img.width > max_width:\n        ratio = max_width / img.width\n        new_height = int(img.height * ratio)\n        img = img.resize((max_width, new_height), Image.Resampling.NEAREST)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\", optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/png\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.get(\"/api/terrain/aspect\")\nasync def get_terrain_aspect(max_width: int = None):\n    \"\"\"取得坡向彩色圖 (PNG with compression)\"\"\"\n    if not terrain_cache[\"computed\"]:\n        raise HTTPException(status_code=400, detail=\"Terrain not computed yet\")\n    from PIL import Image\n    color_img = get_aspect_colorized()\n    if color_img is None:\n        raise HTTPException(status_code=500, detail=\"Failed to generate colorized aspect\")\n    img = Image.fromarray(color_img)\n    if max_width and img.width > max_width:\n        ratio = max_width / img.width\n        new_height = int(img.height * ratio)\n        img = img.resize((max_width, new_height), Image.Resampling.NEAREST)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\", optimize=True)\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/png\",\n                    headers={\"Cache-Control\": \"public, max-age=3600\"})\n\n@app.post(\"/api/terrain/run\")\nasync def run_terrain():\n    if not dsm_cache[\"loaded\"]:\n        raise HTTPException(status_code=400, detail=\"Please upload a DSM first\")\n    try:\n        result = compute_terrain_metrics()\n        return convert_numpy({\"status\": \"done\", \"stats\": result})\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# ============ Processing Endpoints ============\n\n@app.post(\"/api/process\")\nasync def start_processing(request: ProcessingRequest = None):\n    if request is None:\n        request = ProcessingRequest()\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=400, detail=\"Please upload an image first\")\n\n    job_id = f\"job_{int(time.time())}\"\n    processing_state[\"job_id\"] = job_id\n    processing_state[\"status\"] = \"pending\"\n    processing_state[\"progress\"] = 0\n    processing_state[\"start_time\"] = time.time()\n    processing_state[\"results\"] = []\n\n    def update_progress(progress, step):\n        processing_state[\"progress\"] = progress\n        processing_state[\"current_step\"] = step\n        processing_state[\"elapsed_seconds\"] = time.time() - processing_state[\"start_time\"]\n\n    def run():\n        try:\n            processing_state[\"status\"] = \"running\"\n            classes = []\n            if request.detect_vehicle: classes.append(\"car\")\n            if request.detect_person: classes.append(\"person\")\n            if request.detect_cone: classes.append(\"cone\")\n\n            update_progress(10, \"Loading models...\")\n            detections = run_yolo_detection(classes, update_progress)\n\n            if request.include_elevation:\n                update_progress(70, \"Height analysis...\")\n                detections = compute_height_volume(detections, update_progress)\n\n            if request.include_landcover:\n                update_progress(80, \"Landcover segmentation...\")\n                def landcover_progress(p, step):\n                    update_progress(80 + int(p * 0.1), step)\n                run_landcover_segmentation(landcover_progress)\n\n            if request.include_terrain and dsm_cache[\"loaded\"]:\n                update_progress(90, \"Terrain analysis...\")\n                def terrain_progress(p, step):\n                    update_progress(90 + int(p * 0.05), step)\n                compute_terrain_metrics(terrain_progress)\n\n            update_progress(95, \"Coordinate transform...\")\n            detections = add_latlon_to_detections(detections)\n\n            for i, det in enumerate(detections, 1):\n                det[\"id\"] = i\n                det.pop(\"px1\", None)\n                det.pop(\"py1\", None)\n                det.pop(\"px2\", None)\n                det.pop(\"py2\", None)\n\n            processing_state[\"results\"] = detections\n            processing_state[\"status\"] = \"done\"\n            update_progress(100, \"Complete\")\n        except Exception as e:\n            processing_state[\"status\"] = \"error\"\n            processing_state[\"current_step\"] = str(e)\n            import traceback\n            traceback.print_exc()\n\n    threading.Thread(target=run, daemon=True).start()\n    return {\"job_id\": job_id, \"status\": \"started\", \"message\": \"Processing started\"}\n\n@app.get(\"/api/process/status\")\nasync def get_current_processing_status():\n    return {\"job_id\": processing_state[\"job_id\"], \"status\": processing_state[\"status\"],\n            \"progress\": processing_state[\"progress\"], \"current_step\": processing_state[\"current_step\"],\n            \"elapsed_seconds\": time.time() - processing_state[\"start_time\"] if processing_state[\"start_time\"] else 0}\n\n@app.get(\"/api/process/{job_id}/status\")\nasync def get_processing_status(job_id: str):\n    if processing_state[\"job_id\"] != job_id:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    return {\"job_id\": job_id, \"status\": processing_state[\"status\"], \"progress\": processing_state[\"progress\"],\n            \"current_step\": processing_state[\"current_step\"],\n            \"elapsed_seconds\": time.time() - processing_state[\"start_time\"] if processing_state[\"start_time\"] else 0}\n\n@app.get(\"/api/export/stats\")\nasync def export_stats():\n    results = convert_numpy(processing_state[\"results\"])\n    stats = {\"total\": len(results), \"person\": len([r for r in results if r.get(\"cls\") == \"person\"]),\n             \"vehicle\": len([r for r in results if r.get(\"cls\") == \"vehicle\"]),\n             \"cone\": len([r for r in results if r.get(\"cls\") == \"cone\"])}\n    landcover_stats = landcover_cache[\"stats\"] if landcover_cache[\"computed\"] else None\n    terrain_stats = terrain_cache[\"stats\"] if terrain_cache[\"computed\"] else None\n    return convert_numpy({\"generated_at\": datetime.now().isoformat(), \"summary\": stats, \"detections\": results,\n                          \"landcover\": landcover_stats, \"terrain\": terrain_stats})\n\nprint(\"API 程式碼載入完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. 啟動 API Server (Cloudflare Tunnel)\n",
    "import subprocess\n",
    "import threading\n",
    "import re\n",
    "import time\n",
    "\n",
    "# 啟動 cloudflared tunnel\n",
    "def run_cloudflared():\n",
    "    process = subprocess.Popen(\n",
    "        ['/usr/local/bin/cloudflared', 'tunnel', '--url', 'http://localhost:8000'],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    for line in process.stderr:\n",
    "        match = re.search(r'https://[a-z0-9-]+\\.trycloudflare\\.com', line)\n",
    "        if match:\n",
    "            url = match.group(0)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"API URL: {url}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"\\n請複製上方 URL 到前端 Dashboard 連線\\n\")\n",
    "\n",
    "# 啟動 uvicorn\n",
    "import uvicorn\n",
    "\n",
    "def run_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    server.run()\n",
    "\n",
    "# 背景啟動\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "tunnel_thread = threading.Thread(target=run_cloudflared, daemon=True)\n",
    "tunnel_thread.start()\n",
    "\n",
    "print(\"Server 啟動中，請等待 Cloudflare Tunnel URL...\")\n",
    "\n",
    "# 保持運行\n",
    "while True:\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}