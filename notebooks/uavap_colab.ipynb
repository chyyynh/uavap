{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# UAV AIP Detection API (Colab GPU)\n\n在 Google Colab 上執行 UAV 物件偵測 API，使用免費 GPU 加速推論。\n\n## 使用方式\n1. 執行所有 Cell\n2. 複製最後產生的 Cloudflare Tunnel URL\n3. 在前端 Dashboard 貼上 URL 連線"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. 安裝依賴\n!pip install -q fastapi uvicorn nest-asyncio \\\n    ultralytics rasterio laspy pyproj shapely \\\n    segmentation-models-pytorch huggingface_hub pillow\n\n# 安裝 cloudflared\n!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared\n!chmod +x /usr/local/bin/cloudflared\nprint(\"依賴安裝完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. API 程式碼\nimport threading\nimport time\nimport os\nimport shutil\nimport io\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport numpy as np\nfrom fastapi import FastAPI, UploadFile, File, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import Response\nfrom pydantic import BaseModel\n\n# FastAPI App\napp = FastAPI(title=\"UAV Object Detection API - Colab GPU\")\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# 設定\nUPLOAD_DIR = Path(\"/content/uploads\")\nUPLOAD_DIR.mkdir(parents=True, exist_ok=True)\nMODEL_DIR = Path(\"/content/models\")\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\nHF_MODEL_REPO = \"chyyynh/uav-yolo-models\"\n\ndef get_model_path(filename: str) -> Path:\n    cached_path = MODEL_DIR / filename\n    if cached_path.exists():\n        return cached_path\n    try:\n        from huggingface_hub import hf_hub_download\n        print(f\"[Model] Downloading {filename}...\")\n        downloaded = hf_hub_download(repo_id=HF_MODEL_REPO, filename=filename)\n        return Path(downloaded)\n    except Exception as e:\n        print(f\"[Model] Failed: {e}\")\n        return cached_path\n\n# YOLO 設定\nMODELS_CONFIG = {\n    \"car\": {\"filename\": \"vehicle.pt\", \"conf\": 0.75, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (4.0, 25.0), \"ratio\": (1.0, 3.0)},\n    \"person\": {\"filename\": \"human.pt\", \"conf\": 0.60, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (0.2, 1.0), \"ratio\": (0.5, 2.0)},\n    \"cone\": {\"filename\": \"cone.pt\", \"conf\": 0.60, \"patch_size\": 1024, \"overlap\": 850, \"nms_iou\": 0.1, \"area\": (0.05, 0.5), \"ratio\": (0.8, 1.4)},\n}\n\nHEIGHT_RANGE = {\"person\": (1.45, 1.90), \"cone\": (0.25, 0.90), \"car\": (1.0, 2.2), \"vehicle\": (1.0, 2.2)}\nHEIGHT_PRIOR = {\"person\": {\"mean\": 1.70, \"std\": 0.08}, \"cone\": {\"mean\": 0.45, \"std\": 0.10}, \"car\": {\"mean\": 1.60, \"std\": 0.25}, \"vehicle\": {\"mean\": 1.60, \"std\": 0.25}}\nMIN_PTS_BY_CLASS = {\"person\": 8, \"cone\": 10, \"car\": 30}\n\n# UPerNet 設定\nLANDCOVER_CLASSES = {0: \"bare-ground\", 1: \"tree\", 2: \"road\", 3: \"pavement\", 4: \"grass\", 5: \"building\"}\nLANDCOVER_COLORS = {\"bare-ground\": [222, 184, 135], \"tree\": [34, 139, 34], \"road\": [128, 128, 128], \"pavement\": [178, 34, 34], \"grass\": [124, 252, 0], \"building\": [255, 140, 0]}\nUPERNET_CONFIG = {\"filename\": \"UPerNet_best.pth\", \"num_classes\": 6, \"tile_size\": (64, 64), \"overlap\": 0.5, \"encoder_name\": \"resnet50\"}\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\nrng = np.random.default_rng(42)\n\n# 全域狀態\nuploaded_files = {\"ortho\": None, \"laz\": None, \"dsm\": None}\northo_cache = {\"src\": None, \"transform\": None, \"crs\": None, \"bounds\": None, \"width\": 0, \"height\": 0, \"pixel_w\": 0, \"pixel_h\": 0}\npointcloud_cache = {\"X\": None, \"Y\": None, \"Z\": None, \"loaded\": False}\ndsm_cache = {\"data\": None, \"transform\": None, \"crs\": None, \"loaded\": False, \"nodata\": None}\nmodels_cache = {\"loaded\": False, \"models\": {}}\nupernet_cache = {\"loaded\": False, \"model\": None}\nlandcover_cache = {\"mask\": None, \"stats\": None, \"computed\": False}\nprocessing_state = {\"job_id\": None, \"status\": \"idle\", \"progress\": 0, \"current_step\": \"\", \"elapsed_seconds\": 0, \"results\": [], \"start_time\": None}\n\nclass ProcessingRequest(BaseModel):\n    project_id: str = \"current\"\n    detect_person: bool = True\n    detect_vehicle: bool = True\n    detect_cone: bool = True\n    include_elevation: bool = True\n    include_landcover: bool = False\n\ndef load_yolo_models():\n    if models_cache[\"loaded\"]:\n        return models_cache[\"models\"]\n    from ultralytics import YOLO\n    models = {}\n    for cls_name, cfg in MODELS_CONFIG.items():\n        model_path = get_model_path(cfg[\"filename\"])\n        if model_path.exists():\n            models[cls_name] = YOLO(str(model_path))\n            print(f\"[YOLO] Loaded: {cls_name}\")\n    models_cache[\"models\"] = models\n    models_cache[\"loaded\"] = True\n    return models\n\ndef run_yolo_detection(classes_to_detect: list[str], progress_callback=None) -> list[dict]:\n    import rasterio\n    from rasterio.windows import Window\n    import torch\n    from torchvision.ops import nms\n\n    if ortho_cache[\"src\"] is None:\n        raise ValueError(\"No ortho image loaded\")\n\n    src = ortho_cache[\"src\"]\n    transform = ortho_cache[\"transform\"]\n    width, height = ortho_cache[\"width\"], ortho_cache[\"height\"]\n    pixel_w, pixel_h = ortho_cache[\"pixel_w\"], ortho_cache[\"pixel_h\"]\n\n    models = load_yolo_models()\n    if not models:\n        raise ValueError(\"No YOLO models loaded\")\n\n    raw_detections = []\n    total_classes = len(classes_to_detect)\n\n    for cls_idx, cls_name in enumerate(classes_to_detect):\n        if cls_name not in models:\n            continue\n        model = models[cls_name]\n        cfg = MODELS_CONFIG[cls_name]\n        patch_size = cfg[\"patch_size\"]\n        step = patch_size - cfg[\"overlap\"]\n\n        rows = list(range(0, height, step))\n        total_patches = len(rows) * ((width + step - 1) // step)\n        patch_count = 0\n\n        for y in rows:\n            for x in range(0, width, step):\n                win_w, win_h = min(patch_size, width - x), min(patch_size, height - y)\n                patch = src.read(window=Window(x, y, win_w, win_h))\n                patch = np.moveaxis(patch[:3], 0, -1)\n\n                if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n                    padded = np.zeros((patch_size, patch_size, 3), dtype=patch.dtype)\n                    padded[:patch.shape[0], :patch.shape[1]] = patch\n                    patch = padded\n\n                results = model(patch, conf=cfg[\"conf\"], verbose=False)\n                for result in results:\n                    boxes = result.boxes\n                    if boxes is None:\n                        continue\n                    for i in range(len(boxes)):\n                        bx = boxes.xyxy[i].cpu().numpy()\n                        conf = float(boxes.conf[i].cpu())\n                        raw_detections.append({\"class\": cls_name, \"conf\": conf, \"px1\": x + bx[0], \"py1\": y + bx[1], \"px2\": x + bx[2], \"py2\": y + bx[3]})\n\n                patch_count += 1\n                if progress_callback and patch_count % 10 == 0:\n                    progress = 20 + (cls_idx / total_classes) * 50 + (patch_count / total_patches) * (50 / total_classes)\n                    progress_callback(int(progress), f\"Detecting {cls_name}...\")\n\n    print(f\"[YOLO] Raw: {len(raw_detections)}\")\n\n    # NMS\n    final_detections = []\n    for cls_name in classes_to_detect:\n        if cls_name not in MODELS_CONFIG:\n            continue\n        cfg = MODELS_CONFIG[cls_name]\n        cls_raw = [r for r in raw_detections if r[\"class\"] == cls_name]\n        if not cls_raw:\n            continue\n        boxes = torch.tensor([[r[\"px1\"], r[\"py1\"], r[\"px2\"], r[\"py2\"]] for r in cls_raw])\n        scores = torch.tensor([r[\"conf\"] for r in cls_raw])\n        keep = nms(boxes, scores, cfg[\"nms_iou\"])\n        final_detections.extend([cls_raw[int(i)] for i in keep])\n\n    print(f\"[YOLO] After NMS: {len(final_detections)}\")\n\n    # OBIA filter\n    records = []\n    id_counter = {k: 0 for k in MODELS_CONFIG}\n    for r in final_detections:\n        cls_name = r[\"class\"]\n        cfg = MODELS_CONFIG[cls_name]\n        w_m = (r[\"px2\"] - r[\"px1\"]) * pixel_w\n        h_m = (r[\"py2\"] - r[\"py1\"]) * pixel_h\n        area = w_m * h_m\n        aspect = max(w_m, h_m) / (min(w_m, h_m) + 1e-6)\n        if not (cfg[\"area\"][0] <= area <= cfg[\"area\"][1]):\n            continue\n        if not (cfg[\"ratio\"][0] <= aspect <= cfg[\"ratio\"][1]):\n            continue\n\n        id_counter[cls_name] += 1\n        cx, cy = (r[\"px1\"] + r[\"px2\"]) / 2, (r[\"py1\"] + r[\"py2\"]) / 2\n        gx, gy = transform * (cx, cy)\n        records.append({\"id\": id_counter[cls_name], \"cls\": \"vehicle\" if cls_name == \"car\" else cls_name, \"score\": round(r[\"conf\"], 3),\n                        \"center_x\": round(gx, 2), \"center_y\": round(gy, 2), \"area_m2\": round(area, 2), \"aspect_rat\": round(aspect, 2),\n                        \"px1\": r[\"px1\"], \"py1\": r[\"py1\"], \"px2\": r[\"px2\"], \"py2\": r[\"py2\"], \"elev_z\": 0.0, \"height_m\": 0.0, \"lat\": 0.0, \"lon\": 0.0})\n\n    print(f\"[YOLO] After OBIA: {len(records)}\")\n    return records\n\ndef sample_trunc_normal(mean, std, low, high):\n    for _ in range(60):\n        v = rng.normal(mean, std)\n        if low <= v <= high:\n            return float(v)\n    return float(rng.uniform(low, high))\n\ndef impute_height_by_class(cls_name, h_raw, n_pts, min_pts):\n    hmin, hmax = HEIGHT_RANGE.get(cls_name, (0.0, float('inf')))\n    prior = HEIGHT_PRIOR.get(cls_name, {\"mean\": (hmin + hmax) / 2.0, \"std\": 0.1})\n    def draw():\n        return sample_trunc_normal(prior[\"mean\"], prior[\"std\"], hmin, hmax)\n    if n_pts == 0 or not np.isfinite(h_raw) or h_raw < hmin or h_raw > hmax:\n        return draw(), \"imputed\"\n    return float(h_raw), \"ok\"\n\ndef compute_height_volume(detections, progress_callback=None):\n    if not pointcloud_cache[\"loaded\"]:\n        for det in detections:\n            cls = det[\"cls\"] if det[\"cls\"] != \"vehicle\" else \"car\"\n            h, _ = impute_height_by_class(cls, np.nan, 0, 100)\n            det[\"height_m\"] = round(h, 2)\n        return detections\n\n    from shapely.geometry import box\n    X, Y, Z = pointcloud_cache[\"X\"], pointcloud_cache[\"Y\"], pointcloud_cache[\"Z\"]\n    transform = ortho_cache[\"transform\"]\n\n    for det in detections:\n        cls = det[\"cls\"] if det[\"cls\"] != \"vehicle\" else \"car\"\n        px1, py1 = transform * (det[\"px1\"], det[\"py1\"])\n        px2, py2 = transform * (det[\"px2\"], det[\"py2\"])\n        geom = box(min(px1, px2), min(py1, py2), max(px1, px2), max(py1, py2))\n        minx, miny, maxx, maxy = geom.bounds\n        m = (X >= minx) & (X <= maxx) & (Y >= miny) & (Y <= maxy)\n        if np.any(m):\n            zz = Z[m]\n            z0 = float(np.percentile(zz, 5))\n            ztop = float(np.percentile(zz, 95))\n            h_raw = max(0.0, ztop - z0)\n            h_fix, _ = impute_height_by_class(cls, h_raw, len(zz), MIN_PTS_BY_CLASS.get(cls, 30))\n            det[\"height_m\"] = round(h_fix, 2)\n            det[\"elev_z\"] = round(z0, 1)\n        else:\n            h, _ = impute_height_by_class(cls, np.nan, 0, 100)\n            det[\"height_m\"] = round(h, 2)\n    return detections\n\ndef add_latlon_to_detections(detections):\n    if ortho_cache[\"crs\"] is None:\n        return detections\n    try:\n        from pyproj import Transformer\n        transformer = Transformer.from_crs(ortho_cache[\"crs\"], \"EPSG:4326\", always_xy=True)\n        for det in detections:\n            lon, lat = transformer.transform(det[\"center_x\"], det[\"center_y\"])\n            det[\"lat\"], det[\"lon\"] = round(lat, 6), round(lon, 6)\n    except Exception as e:\n        print(f\"[Coord] Error: {e}\")\n    return detections\n\ndef load_ortho_image(tiff_path):\n    import rasterio\n    src = rasterio.open(tiff_path)\n    ortho_cache[\"src\"] = src\n    ortho_cache[\"transform\"] = src.transform\n    ortho_cache[\"crs\"] = src.crs\n    ortho_cache[\"width\"], ortho_cache[\"height\"] = src.width, src.height\n    ortho_cache[\"pixel_w\"], ortho_cache[\"pixel_h\"] = src.res\n    bounds = src.bounds\n    try:\n        from pyproj import Transformer\n        transformer = Transformer.from_crs(src.crs, \"EPSG:4326\", always_xy=True)\n        west, south = transformer.transform(bounds.left, bounds.bottom)\n        east, north = transformer.transform(bounds.right, bounds.top)\n        ortho_cache[\"bounds\"] = {\"north\": north, \"south\": south, \"east\": east, \"west\": west}\n    except:\n        ortho_cache[\"bounds\"] = {\"north\": bounds.top, \"south\": bounds.bottom, \"east\": bounds.right, \"west\": bounds.left}\n    print(f\"[Ortho] Loaded: {src.width}x{src.height}\")\n\ndef load_point_cloud(laz_path):\n    import laspy\n    las = laspy.read(laz_path)\n    pointcloud_cache[\"X\"] = np.asarray(las.x)\n    pointcloud_cache[\"Y\"] = np.asarray(las.y)\n    pointcloud_cache[\"Z\"] = np.asarray(las.z)\n    pointcloud_cache[\"loaded\"] = True\n    print(f\"[PointCloud] Loaded {len(pointcloud_cache['Z'])} points\")\n\ndef load_dsm(dsm_path):\n    import rasterio\n    src = rasterio.open(dsm_path)\n    dsm_cache[\"data\"] = src.read(1)\n    dsm_cache[\"transform\"] = src.transform\n    dsm_cache[\"crs\"] = src.crs\n    dsm_cache[\"nodata\"] = src.nodata\n    dsm_cache[\"loaded\"] = True\n    dsm_cache[\"resolution\"] = src.res[0]\n    print(f\"[DSM] Loaded: {src.width}x{src.height}\")\n    src.close()\n\ndef convert_numpy(obj):\n    if isinstance(obj, dict):\n        return {k: convert_numpy(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_numpy(v) for v in obj]\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    return obj\n\n# API 端點\n@app.get(\"/\")\nasync def root():\n    return {\"status\": \"ok\", \"message\": \"UAV Object Detection API - Colab GPU\"}\n\n@app.get(\"/api/projects\")\nasync def get_projects():\n    return [{\"id\": \"current\", \"name\": \"Current Project\"}]\n\n@app.get(\"/api/detections/{project_id}\")\nasync def get_detections(project_id: str):\n    return convert_numpy(processing_state[\"results\"] or [])\n\n@app.get(\"/api/gpu/status\")\nasync def get_gpu_status():\n    try:\n        import torch\n        if torch.cuda.is_available():\n            return {\"name\": torch.cuda.get_device_name(0), \"status\": \"online\"}\n    except:\n        pass\n    return {\"name\": \"CPU Mode\", \"status\": \"offline\"}\n\n@app.get(\"/api/ortho/bounds\")\nasync def get_ortho_bounds():\n    return ortho_cache[\"bounds\"] or {\"error\": \"No image loaded\"}\n\n@app.get(\"/api/ortho/image\")\nasync def get_ortho_image():\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=404, detail=\"No image loaded\")\n    from PIL import Image\n    src = ortho_cache[\"src\"]\n    data = src.read([1, 2, 3])\n    data = np.moveaxis(data, 0, -1)\n    if data.dtype != np.uint8:\n        data = ((data - data.min()) / (data.max() - data.min() + 1e-6) * 255).astype(np.uint8)\n    img = Image.fromarray(data)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\")\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/png\")\n\n@app.get(\"/api/ortho/preview\")\nasync def get_ortho_preview(width: int = 800, height: int = 600):\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=404, detail=\"No image loaded\")\n    from PIL import Image\n    src = ortho_cache[\"src\"]\n    data = src.read([1, 2, 3])\n    data = np.moveaxis(data, 0, -1)\n    if data.dtype != np.uint8:\n        data = ((data - data.min()) / (data.max() - data.min() + 1e-6) * 255).astype(np.uint8)\n    img = Image.fromarray(data)\n    img.thumbnail((width, height), Image.Resampling.LANCZOS)\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\")\n    buffer.seek(0)\n    return Response(content=buffer.getvalue(), media_type=\"image/png\")\n\n@app.get(\"/api/ortho/metadata\")\nasync def get_ortho_metadata():\n    if ortho_cache[\"src\"] is None:\n        return {\"error\": \"No image loaded\"}\n    src = ortho_cache[\"src\"]\n    return {\"filename\": Path(uploaded_files[\"ortho\"]).name if uploaded_files[\"ortho\"] else None,\n            \"datetime\": datetime.now().isoformat(), \"width\": src.width, \"height\": src.height,\n            \"crs\": str(src.crs) if src.crs else None}\n\n@app.post(\"/api/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    filename = file.filename.lower()\n    file_path = UPLOAD_DIR / file.filename\n    with open(file_path, \"wb\") as f:\n        shutil.copyfileobj(file.file, f)\n    if filename.endswith((\".tif\", \".tiff\")):\n        uploaded_files[\"ortho\"] = str(file_path)\n        load_ortho_image(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"Image uploaded\", \"type\": \"ortho\"}\n    elif filename.endswith((\".laz\", \".las\")):\n        uploaded_files[\"laz\"] = str(file_path)\n        load_point_cloud(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"Point cloud uploaded\", \"type\": \"laz\", \"points\": len(pointcloud_cache[\"Z\"])}\n    return {\"filename\": file.filename, \"message\": \"File uploaded\", \"type\": \"unknown\"}\n\n@app.post(\"/api/upload/dsm\")\nasync def upload_dsm(file: UploadFile = File(...)):\n    filename = file.filename.lower()\n    file_path = UPLOAD_DIR / file.filename\n    with open(file_path, \"wb\") as f:\n        shutil.copyfileobj(file.file, f)\n    if filename.endswith((\".tif\", \".tiff\")):\n        uploaded_files[\"dsm\"] = str(file_path)\n        load_dsm(str(file_path))\n        return {\"filename\": file.filename, \"message\": \"DSM uploaded\", \"type\": \"dsm\", \"resolution\": dsm_cache.get(\"resolution\")}\n    raise HTTPException(status_code=400, detail=\"DSM must be a GeoTIFF file\")\n\n@app.post(\"/api/process\")\nasync def start_processing(request: ProcessingRequest = None):\n    if request is None:\n        request = ProcessingRequest()\n    if ortho_cache[\"src\"] is None:\n        raise HTTPException(status_code=400, detail=\"Please upload an image first\")\n\n    job_id = f\"job_{int(time.time())}\"\n    processing_state[\"job_id\"] = job_id\n    processing_state[\"status\"] = \"pending\"\n    processing_state[\"progress\"] = 0\n    processing_state[\"start_time\"] = time.time()\n    processing_state[\"results\"] = []\n\n    def update_progress(progress, step):\n        processing_state[\"progress\"] = progress\n        processing_state[\"current_step\"] = step\n        processing_state[\"elapsed_seconds\"] = time.time() - processing_state[\"start_time\"]\n\n    def run():\n        try:\n            processing_state[\"status\"] = \"running\"\n            classes = []\n            if request.detect_vehicle: classes.append(\"car\")\n            if request.detect_person: classes.append(\"person\")\n            if request.detect_cone: classes.append(\"cone\")\n\n            update_progress(10, \"Loading models...\")\n            detections = run_yolo_detection(classes, update_progress)\n\n            if request.include_elevation:\n                update_progress(70, \"Height analysis...\")\n                detections = compute_height_volume(detections, update_progress)\n\n            update_progress(95, \"Coordinate transform...\")\n            detections = add_latlon_to_detections(detections)\n\n            for i, det in enumerate(detections, 1):\n                det[\"id\"] = i\n                det.pop(\"px1\", None)\n                det.pop(\"py1\", None)\n                det.pop(\"px2\", None)\n                det.pop(\"py2\", None)\n\n            processing_state[\"results\"] = detections\n            processing_state[\"status\"] = \"done\"\n            update_progress(100, \"Complete\")\n        except Exception as e:\n            processing_state[\"status\"] = \"error\"\n            processing_state[\"current_step\"] = str(e)\n            import traceback\n            traceback.print_exc()\n\n    threading.Thread(target=run, daemon=True).start()\n    return {\"job_id\": job_id, \"status\": \"started\", \"message\": \"Processing started\"}\n\n@app.get(\"/api/process/status\")\nasync def get_current_processing_status():\n    return {\"job_id\": processing_state[\"job_id\"], \"status\": processing_state[\"status\"],\n            \"progress\": processing_state[\"progress\"], \"current_step\": processing_state[\"current_step\"],\n            \"elapsed_seconds\": time.time() - processing_state[\"start_time\"] if processing_state[\"start_time\"] else 0}\n\n@app.get(\"/api/process/{job_id}/status\")\nasync def get_processing_status(job_id: str):\n    if processing_state[\"job_id\"] != job_id:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    return {\"job_id\": job_id, \"status\": processing_state[\"status\"], \"progress\": processing_state[\"progress\"],\n            \"current_step\": processing_state[\"current_step\"],\n            \"elapsed_seconds\": time.time() - processing_state[\"start_time\"] if processing_state[\"start_time\"] else 0}\n\n@app.get(\"/api/export/stats\")\nasync def export_stats():\n    results = convert_numpy(processing_state[\"results\"])\n    stats = {\"total\": len(results), \"person\": len([r for r in results if r.get(\"cls\") == \"person\"]),\n             \"vehicle\": len([r for r in results if r.get(\"cls\") == \"vehicle\"]),\n             \"cone\": len([r for r in results if r.get(\"cls\") == \"cone\"])}\n    return {\"generated_at\": datetime.now().isoformat(), \"summary\": stats, \"detections\": results}\n\nprint(\"API 程式碼載入完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. 啟動 API Server (Cloudflare Tunnel)\nimport subprocess\nimport threading\nimport re\nimport nest_asyncio\nimport uvicorn\n\nnest_asyncio.apply()\n\n# 啟動 cloudflared tunnel\ndef run_cloudflared():\n    process = subprocess.Popen(\n        ['/usr/local/bin/cloudflared', 'tunnel', '--url', 'http://localhost:8000'],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True\n    )\n    for line in process.stderr:\n        # 找到 trycloudflare.com URL\n        match = re.search(r'https://[a-z0-9-]+\\.trycloudflare\\.com', line)\n        if match:\n            url = match.group(0)\n            print(f\"\\n{'='*60}\")\n            print(f\"API URL: {url}\")\n            print(f\"{'='*60}\")\n            print(f\"\\n請複製上方 URL 到前端 Dashboard 連線\\n\")\n\n# 背景執行 cloudflared\ntunnel_thread = threading.Thread(target=run_cloudflared, daemon=True)\ntunnel_thread.start()\n\nimport time\ntime.sleep(3)  # 等待 tunnel 建立\n\n# 啟動 FastAPI server\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}